{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon_satellite_baseline",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curiosity806/2020_dacon_satellite_precipitation/blob/hotfix%2Fbaseline/Dacon_satellite_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsaIvLKHsjva",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi-MWY4HOblX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6La-zpczGzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dropout, MaxPooling2D, BatchNormalization, concatenate, Input\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKjP-Uobze5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 재생산성을 위해 시드 고정\n",
        "np.random.seed(7)\n",
        "random.seed(7)\n",
        "tf.random.set_seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pUOc4bq-IrZ",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 받아오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1iW93kj0O2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not shuffled data\n",
        "train = np.load('/content/drive/My Drive/2020 Kaggle Study/data/train.npy')  # float32\n",
        "test = np.load('/content/drive/My Drive/2020 Kaggle Study/data/test.npy')  # float64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdf3I-l9fJny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gmi_preci = np.load('/content/drive/My Drive/2020 Kaggle Study/data/gmi_preci.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBPp8ebseqp",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCpO8Eenso9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -9999를 포함한 이미지 제거\n",
        "is_valid = (train[:,:,:,-1].reshape(-1, 1600) < 0).sum(axis=1) == 0\n",
        "train = train[is_valid]  # (75957, 40, 40, 15)\n",
        "gmi_preci = gmi_preci[is_valid]  # (75957, 40, 40, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3Gcx_uZv8xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train[:,:,:,:9].reshape(-1, 9))\n",
        "\n",
        "def preprocess(data):\n",
        "    # Normalize sensor data\n",
        "    data[:,:,:,:9] = scaler.transform(data[:,:,:,:9].reshape(-1, 9)).reshape(-1, 40, 40, 9)\n",
        "\n",
        "    # Land type\n",
        "    land_type_data = data[:,:,:,9]\n",
        "    data[:,:,:,9] = np.where(land_type_data//100 == 2, 0.8,\n",
        "                              np.where(land_type_data//100 == 3, 0.1,\n",
        "                                       land_type_data//100))\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGj-ULPdRw4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = preprocess(train)[:,:,:,:10]\n",
        "y_train = gmi_preci.reshape(-1, 40, 40)\n",
        "del train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-S9OXyd9K-a",
        "colab_type": "text"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsowKWD39Qsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.025, random_state=7777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYZYG3G-Itsk"
      },
      "source": [
        "## 모델만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_NhbS4s09p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def mae(y_true, y_pred) :\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    over_threshold = y_true >= 0.1\n",
        "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    remove_NAs = y_true >= 0\n",
        "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
        "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
        "    return(f1_score(y_true, y_pred))\n",
        "\n",
        "def maeOverFscore(y_true, y_pred):\n",
        "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
        "\n",
        "def fscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
        "    return score\n",
        "\n",
        "def maeOverFscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vBZ09E8JZpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_layer, start_neurons):\n",
        "    # 40 x 40 -> 20 x 20\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
        "    pool1 = BatchNormalization()(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(pool1)\n",
        "    pool1 = Dropout(0.25)(pool1)\n",
        "\n",
        "    # 20 x 20 -> 10 x 10\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
        "    pool2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(pool2)\n",
        "    pool2 = Dropout(0.25)(pool2)\n",
        "\n",
        "    # 10 x 10 \n",
        "    convm = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
        "\n",
        "    # 10 x 10 -> 20 x 20\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "    uconv2 = Dropout(0.25)(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "\n",
        "    # 20 x 20 -> 40 x 40\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "    uconv1 = Dropout(0.25)(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Dropout(0.25)(uconv1)\n",
        "    output_layer = Conv2D(1, (1, 1), padding=\"same\", activation='relu')(uconv1)\n",
        "\n",
        "    return output_layer\n",
        "\n",
        "input_layer = Input((40, 40, 10))\n",
        "output_layer = build_model(input_layer, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv7Hk_LM1DNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(input_layer, output_layer)\n",
        "model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nWrybUnXIts7"
      },
      "source": [
        "## 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLaFxud8iNXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, epochs=1, batch_size=256, validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoowuSxyZgLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 모델 저장하기\n",
        "model.save('model1816.h5')\n",
        "!cp model1816.h5 '/content/drive/My Drive/2020 Kaggle Study/model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjmLe8t7j8cN",
        "colab_type": "text"
      },
      "source": [
        "## Precipatation GMI -> DPR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyTSFuEGkEd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dr = [(-1, -1), (-1, 0), (-1, 1),\n",
        "      (0, -1), (0, 0), (0, 1),\n",
        "      (1, -1), (1, 0), (1, 1)]\n",
        "\n",
        "# p1, p2: shape=(-1, 2).\n",
        "def get_dist(p1, p2):\n",
        "    x1 = np.deg2rad(p1[:,0])\n",
        "    y1 = np.deg2rad(p1[:,1])\n",
        "    x2 = np.deg2rad(p2[:,0])\n",
        "    y2 = np.deg2rad(p2[:,1])\n",
        "    dlon = x2 - x1\n",
        "    dlat = y2 - y1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(y1) * np.cos(y2) * np.sin(dlon/2)**2 \n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))    \n",
        "    return 6373.0 * c  # km, shape=(-1).\n",
        "\n",
        "# ori_ll에서의 value 값을 tgt_ll에 대한 값으로 바꾼다.\n",
        "# value: (40, 40, -1)\n",
        "# ori_ll, tgt_ll: (40, 40, 2)\n",
        "# ori_ll: value에 대응되는 원래 latitude, longitude.\n",
        "# tgt_ll: 변환되는 값에 대응되는 latitude, longitude.\n",
        "def compen_ll(value, ori_ll, tgt_ll):\n",
        "    ret = np.empty_like(value)\n",
        "\n",
        "    n = value.shape[0]\n",
        "    m = value.shape[1]\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            nears = []  # (row, col, value)\n",
        "            for k in range(9):\n",
        "                ii = i + dr[k][0]\n",
        "                jj = j + dr[k][1]\n",
        "                if ii >= 0 and ii < n and jj >= 0 and jj < m:\n",
        "                    nears.append((ori_ll[ii, jj][0], ori_ll[ii, jj][1],\n",
        "                                  tgt_ll[i, j][0], tgt_ll[i, j][1],\n",
        "                                  value[ii, jj]))\n",
        "\n",
        "            nears = np.array(nears)  # shape=(-1, 5)\n",
        "            dists = get_dist(nears[:, 0:2], nears[:, 2:4]).reshape(-1, 1)\n",
        "            values = nears[:, 4].reshape(-1, 1)\n",
        "            nears = np.concatenate((dists, values), 1)\n",
        "            nears = nears[np.argsort(nears[:, 0])]  # sort by dist\n",
        "            nears = nears[:4, :]  # 가까운 점 4개만 고려\n",
        "\n",
        "            weights = 1 / (nears[:, 0] ** 2 + sys.float_info.epsilon)\n",
        "            weighted_sum = (weights * nears[:, 1]).sum()\n",
        "            ret[i, j] = weighted_sum / weights.sum()\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG9A32a6qyyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = preprocess(test)\n",
        "pred = model.predict(x_test[:,:,:,:10]).reshape(-1, 40, 40, 1)\n",
        "test = np.concatenate((x_test, pred), axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSTjD9TqqRXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Process, Manager\n",
        "\n",
        "n_procs = 4\n",
        "procs = []\n",
        "manager = Manager()\n",
        "dpr_preci = manager.list([None] * n_procs)\n",
        "\n",
        "# split test into n_procs arrays\n",
        "n_imgs = test.shape[0]\n",
        "splitted = np.split(test, np.arange((n_imgs + n_procs - 1) // n_procs, n_imgs, n_imgs // n_procs))\n",
        "\n",
        "def proc_func(proc_id):\n",
        "    part = splitted[proc_id]\n",
        "    arr = np.empty_like(part[:, :, :, 14])  # shape=(-1, 40, 40)\n",
        "    for i in range(part.shape[0]):\n",
        "        arr[i, :, :] = compen_ll(part[i, :, :, 14],\n",
        "                                 part[i, :, :, 12:14],\n",
        "                                 part[i, :, :, 10:12])\n",
        "        if (i + 1) % 1000 == 0:\n",
        "            print(proc_id, i + 1)\n",
        "    dpr_preci[proc_id] = arr\n",
        "\n",
        "for proc_id in range(n_procs):\n",
        "    proc = Process(target=proc_func, args=(proc_id, ))\n",
        "    proc.start()\n",
        "    procs.append(proc)\n",
        "\n",
        "for proc in procs:\n",
        "    proc.join()\n",
        "\n",
        "dpr_preci = np.concatenate(dpr_preci)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2xM7q7FpIttP"
      },
      "source": [
        "## submission 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BaAuaIqhh_z3",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('/content/drive/My Drive/2020 Kaggle Study/data/sample_submission.csv')\n",
        "submission.iloc[:,1:] = dpr_preci.reshape(-1, 1600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fBTzEKnh_0B",
        "colab": {}
      },
      "source": [
        "# 제출 파일 저장하기\n",
        "submission.to_csv('submission1816.csv', index=False)\n",
        "!cp submission1816.csv '/content/drive/My Drive/2020 Kaggle Study/submission'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}