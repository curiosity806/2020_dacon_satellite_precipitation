{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon_satellite_baseline.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curiosity806/2020_dacon_satellite_precipitation/blob/augment8%2Fresnet-single/Dacon_satellite_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsaIvLKHsjva",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi-MWY4HOblX",
        "colab_type": "code",
        "outputId": "85f336af-ec5e-4488-c2f8-f3fb4860f07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6La-zpczGzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dropout, MaxPooling2D, BatchNormalization, concatenate, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.utils import Sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKjP-Uobze5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 재생산성을 위해 시드 고정\n",
        "np.random.seed(7)\n",
        "random.seed(7)\n",
        "tf.random.set_seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pUOc4bq-IrZ",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 받아오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1iW93kj0O2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path\n",
        "if not os.path.isfile('train.npy'):\n",
        "    !cp '/content/drive/My Drive/2020 Kaggle Study/data/train.npy' train.npy\n",
        "if not os.path.isfile('test.npy'): \n",
        "    !cp '/content/drive/My Drive/2020 Kaggle Study/data/test.npy' test.npy\n",
        "if not os.path.isfile('gmi_preci.npy'):\n",
        "    !cp '/content/drive/My Drive/2020 Kaggle Study/data/gmi_preci/near2.npy' gmi_preci.npy\n",
        "\n",
        "train = np.load('train.npy')  # float32\n",
        "test = np.load('test.npy')  # float64\n",
        "gmi_preci = np.load('gmi_preci.npy')  # float32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-S9OXyd9K-a",
        "colab_type": "text"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsowKWD39Qsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val, train_preci, val_preci = train_test_split(train, gmi_preci, test_size=0.025, random_state=7777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBPp8ebseqp",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvWPfvODBb68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.concatenate((train[:, :, :, :10], train[:, :, :, -1:]), axis=3)  # sensor, land type, target만 남기기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7H48bWMneXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[:, :, :, -1] = train_preci.reshape(-1, 40, 40)  # GMI precipatation으로 대치"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3Gcx_uZv8xW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5db8a354-826e-41ab-bef4-0ea44c4e6b7f"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(train[:,:,:,:9].reshape(-1, 9))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-kN_kbFhLZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data):\n",
        "    # Normalize sensor data\n",
        "    data[:,:,:,:9] = scaler.transform(data[:,:,:,:9].reshape(-1, 9)).reshape(-1, 40, 40, 9)\n",
        "\n",
        "    # Land type\n",
        "    land_type_data = data[:,:,:,9]\n",
        "    data[:,:,:,9] = np.where(land_type_data//100 == 2, 0.7,\n",
        "                             np.where(land_type_data//100 == 3, 0.3,\n",
        "                                      land_type_data//100))\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCpO8Eenso9k",
        "colab_type": "code",
        "outputId": "b460d1e0-2702-4fb0-dcbb-198a5b182908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# -9999를 포함한 이미지, 강수인 지역이 300픽셀 미만인 이미지 제거\n",
        "# land type이 ocean이 아닌 이미지 살리기\n",
        "is_valid = (train[:,:,:,-1].reshape(-1, 1600) >= 0.1).sum(axis=1) >= 300\n",
        "is_valid = is_valid | ((train[:,:,:,9].reshape(-1, 1600) >= 100).sum(axis=1) >= 300)\n",
        "is_valid = is_valid & ((train[:,:,:,-1].reshape(-1, 1600) < 0).sum(axis=1) == 0)\n",
        "train = train[is_valid]  # (-1, 40, 40, 15)\n",
        "train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31751, 40, 40, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGj-ULPdRw4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = preprocess(train)\n",
        "val = preprocess(val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUGkDFCTqVSw",
        "colab_type": "text"
      },
      "source": [
        "## Rotation-flip augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5WMJFagqZpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def r(a, n=1):\n",
        "    return np.rot90(a, n, (1, 2))\n",
        "\n",
        "def f_ud(a):\n",
        "    return np.flip(a, 1)\n",
        "\n",
        "def f_lr(a):\n",
        "    return np.flip(a, 2)\n",
        "\n",
        "def t(a):\n",
        "    return np.transpose(a, (0, 2, 1, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zte0DnFAqbWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abcd = train\n",
        "acbd = r(f_lr(train))\n",
        "badc = f_lr(train)\n",
        "bdac = r(train)\n",
        "cadb = r(train, 3)\n",
        "cdab = f_ud(train)\n",
        "dbca = t(r(train, 2))\n",
        "dcba = r(train, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYZYG3G-Itsk"
      },
      "source": [
        "## 모델만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_NhbS4s09p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def mae(y_true, y_pred) :\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    over_threshold = y_true >= 0.1\n",
        "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    remove_NAs = y_true >= 0\n",
        "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
        "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
        "    return(f1_score(y_true, y_pred))\n",
        "\n",
        "def maeOverFscore(y_true, y_pred):\n",
        "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
        "\n",
        "def fscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
        "    return score\n",
        "\n",
        "def maeOverFscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vBZ09E8JZpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    inputs=Input((40, 40, 10))\n",
        "    \n",
        "    conv0=Conv2D(256, kernel_size=1, strides=1, padding='same', activation='relu')(inputs)\n",
        "    conv0=Dropout(0.5)(conv0)\n",
        "    \n",
        "    bn=BatchNormalization()(conv0)\n",
        "    conv=Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
        "    conv=Dropout(0.5)(conv)\n",
        "    concat=concatenate([conv0, conv], axis=3)\n",
        "    \n",
        "    bn=BatchNormalization()(concat)\n",
        "    conv=Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
        "    conv=Dropout(0.5)(conv)\n",
        "    concat=concatenate([concat, conv], axis=3)\n",
        "\n",
        "    for i in range(5):\n",
        "        bn=BatchNormalization()(concat)\n",
        "        conv=Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
        "        conv=Dropout(0.5)(conv)\n",
        "        concat=concatenate([concat, conv], axis=3)\n",
        "    \n",
        "    bn=BatchNormalization()(concat)\n",
        "    outputs=Conv2D(1, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "    \n",
        "    model=Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nWrybUnXIts7"
      },
      "source": [
        "## 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP9Q5OsA_CHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a56592ba-a6af-489b-8c3d-aded02df5c51"
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brkWZJad6f8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94e4893e-77c0-4719-97e3-7390bac26931"
      },
      "source": [
        "x_val, y_val = val[:, :, :, :10], val[:, :, :, -1]\n",
        "train_data = [[abcd, acbd, badc, bdac], [cadb, cdab, dbca, dcba]]\n",
        "\n",
        "models = []\n",
        "for t in train_data:\n",
        "    _train = np.concatenate(t)\n",
        "    x_train, y_train = _train[:, :, :, :10], _train[:, :, :, -1]\n",
        "\n",
        "    # with tpu_strategy.scope():\n",
        "    model = create_model()\n",
        "    model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_maeOverFscore_keras', patience=5)\n",
        "    model.fit(x_train, y_train, epochs=50, batch_size=128, validation_data=(x_val, val_preci), callbacks=[early_stopping])  # batch_size 128 넘으면 안 됨\n",
        "    models.append(model)\n",
        "\n",
        "    del x_train, y_train\n",
        "    del _train\n",
        "    gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "993/993 [==============================] - 365s 368ms/step - loss: 0.1820 - maeOverFscore_keras: 2.0714 - fscore_keras: 0.7405 - val_loss: 65.8328 - val_maeOverFscore_keras: 1.6349 - val_fscore_keras: 0.7165\n",
            "Epoch 2/50\n",
            "993/993 [==============================] - 363s 365ms/step - loss: 0.1609 - maeOverFscore_keras: 1.7074 - fscore_keras: 0.7946 - val_loss: 65.8296 - val_maeOverFscore_keras: 1.5641 - val_fscore_keras: 0.7218\n",
            "Epoch 3/50\n",
            "993/993 [==============================] - 362s 365ms/step - loss: 0.1577 - maeOverFscore_keras: 1.6541 - fscore_keras: 0.8043 - val_loss: 65.8280 - val_maeOverFscore_keras: 1.4904 - val_fscore_keras: 0.7420\n",
            "Epoch 4/50\n",
            "993/993 [==============================] - 360s 363ms/step - loss: 0.1558 - maeOverFscore_keras: 1.6241 - fscore_keras: 0.8091 - val_loss: 65.8282 - val_maeOverFscore_keras: 1.4816 - val_fscore_keras: 0.7460\n",
            "Epoch 5/50\n",
            "993/993 [==============================] - 361s 364ms/step - loss: 0.1545 - maeOverFscore_keras: 1.6031 - fscore_keras: 0.8125 - val_loss: 65.8269 - val_maeOverFscore_keras: 1.4474 - val_fscore_keras: 0.7521\n",
            "Epoch 6/50\n",
            "993/993 [==============================] - 360s 363ms/step - loss: 0.1539 - maeOverFscore_keras: 1.5937 - fscore_keras: 0.8132 - val_loss: 65.8271 - val_maeOverFscore_keras: 1.4508 - val_fscore_keras: 0.7497\n",
            "Epoch 7/50\n",
            "993/993 [==============================] - 360s 363ms/step - loss: 0.1532 - maeOverFscore_keras: 1.5844 - fscore_keras: 0.8154 - val_loss: 65.8272 - val_maeOverFscore_keras: 1.4559 - val_fscore_keras: 0.7521\n",
            "Epoch 8/50\n",
            "993/993 [==============================] - 362s 364ms/step - loss: 0.1525 - maeOverFscore_keras: 1.5698 - fscore_keras: 0.8173 - val_loss: 65.8263 - val_maeOverFscore_keras: 1.4469 - val_fscore_keras: 0.7506\n",
            "Epoch 9/50\n",
            "993/993 [==============================] - 361s 363ms/step - loss: 0.1521 - maeOverFscore_keras: 1.5669 - fscore_keras: 0.8182 - val_loss: 65.8258 - val_maeOverFscore_keras: 1.4212 - val_fscore_keras: 0.7547\n",
            "Epoch 10/50\n",
            "993/993 [==============================] - 360s 363ms/step - loss: 0.1517 - maeOverFscore_keras: 1.5618 - fscore_keras: 0.8188 - val_loss: 65.8265 - val_maeOverFscore_keras: 1.4817 - val_fscore_keras: 0.7382\n",
            "Epoch 11/50\n",
            "993/993 [==============================] - 362s 364ms/step - loss: 0.1514 - maeOverFscore_keras: 1.5561 - fscore_keras: 0.8199 - val_loss: 65.8256 - val_maeOverFscore_keras: 1.4231 - val_fscore_keras: 0.7550\n",
            "Epoch 12/50\n",
            "993/993 [==============================] - 364s 366ms/step - loss: 0.1510 - maeOverFscore_keras: 1.5486 - fscore_keras: 0.8209 - val_loss: 65.8252 - val_maeOverFscore_keras: 1.3969 - val_fscore_keras: 0.7634\n",
            "Epoch 13/50\n",
            "993/993 [==============================] - 362s 364ms/step - loss: 0.1512 - maeOverFscore_keras: 1.5521 - fscore_keras: 0.8204 - val_loss: 65.8255 - val_maeOverFscore_keras: 1.3828 - val_fscore_keras: 0.7664\n",
            "Epoch 14/50\n",
            "993/993 [==============================] - 362s 365ms/step - loss: 0.1505 - maeOverFscore_keras: 1.5433 - fscore_keras: 0.8225 - val_loss: 65.8251 - val_maeOverFscore_keras: 1.3926 - val_fscore_keras: 0.7623\n",
            "Epoch 15/50\n",
            "993/993 [==============================] - 359s 362ms/step - loss: 0.1505 - maeOverFscore_keras: 1.5413 - fscore_keras: 0.8222 - val_loss: 65.8264 - val_maeOverFscore_keras: 1.4515 - val_fscore_keras: 0.7495\n",
            "Epoch 16/50\n",
            "993/993 [==============================] - 362s 365ms/step - loss: 0.1503 - maeOverFscore_keras: 1.5396 - fscore_keras: 0.8225 - val_loss: 65.8256 - val_maeOverFscore_keras: 1.4105 - val_fscore_keras: 0.7611\n",
            "Epoch 17/50\n",
            "993/993 [==============================] - 360s 362ms/step - loss: 0.1500 - maeOverFscore_keras: 1.5341 - fscore_keras: 0.8232 - val_loss: 65.8260 - val_maeOverFscore_keras: 1.4195 - val_fscore_keras: 0.7601\n",
            "Epoch 18/50\n",
            "993/993 [==============================] - 361s 364ms/step - loss: 0.1497 - maeOverFscore_keras: 1.5302 - fscore_keras: 0.8239 - val_loss: 65.8261 - val_maeOverFscore_keras: 1.4091 - val_fscore_keras: 0.7645\n",
            "Epoch 1/50\n",
            "993/993 [==============================] - 362s 364ms/step - loss: 0.1863 - maeOverFscore_keras: 2.1582 - fscore_keras: 0.7284 - val_loss: 65.8329 - val_maeOverFscore_keras: 1.6484 - val_fscore_keras: 0.7115\n",
            "Epoch 2/50\n",
            "993/993 [==============================] - 363s 366ms/step - loss: 0.1615 - maeOverFscore_keras: 1.7170 - fscore_keras: 0.7933 - val_loss: 65.8301 - val_maeOverFscore_keras: 1.5864 - val_fscore_keras: 0.7174\n",
            "Epoch 3/50\n",
            "993/993 [==============================] - 362s 365ms/step - loss: 0.1581 - maeOverFscore_keras: 1.6590 - fscore_keras: 0.8039 - val_loss: 65.8291 - val_maeOverFscore_keras: 1.5432 - val_fscore_keras: 0.7308\n",
            "Epoch 4/50\n",
            "993/993 [==============================] - 362s 364ms/step - loss: 0.1560 - maeOverFscore_keras: 1.6250 - fscore_keras: 0.8096 - val_loss: 65.8278 - val_maeOverFscore_keras: 1.4689 - val_fscore_keras: 0.7483\n",
            "Epoch 5/50\n",
            "993/993 [==============================] - 361s 363ms/step - loss: 0.1549 - maeOverFscore_keras: 1.6081 - fscore_keras: 0.8122 - val_loss: 65.8281 - val_maeOverFscore_keras: 1.4665 - val_fscore_keras: 0.7482\n",
            "Epoch 6/50\n",
            "993/993 [==============================] - 358s 360ms/step - loss: 0.1544 - maeOverFscore_keras: 1.5978 - fscore_keras: 0.8133 - val_loss: 65.8270 - val_maeOverFscore_keras: 1.4468 - val_fscore_keras: 0.7498\n",
            "Epoch 7/50\n",
            "993/993 [==============================] - 361s 364ms/step - loss: 0.1535 - maeOverFscore_keras: 1.5878 - fscore_keras: 0.8154 - val_loss: 65.8270 - val_maeOverFscore_keras: 1.4388 - val_fscore_keras: 0.7560\n",
            "Epoch 8/50\n",
            "993/993 [==============================] - 362s 365ms/step - loss: 0.1528 - maeOverFscore_keras: 1.5726 - fscore_keras: 0.8174 - val_loss: 65.8266 - val_maeOverFscore_keras: 1.4610 - val_fscore_keras: 0.7468\n",
            "Epoch 9/50\n",
            "993/993 [==============================] - 361s 363ms/step - loss: 0.1523 - maeOverFscore_keras: 1.5686 - fscore_keras: 0.8186 - val_loss: 65.8261 - val_maeOverFscore_keras: 1.4309 - val_fscore_keras: 0.7544\n",
            "Epoch 10/50\n",
            "993/993 [==============================] - 361s 364ms/step - loss: 0.1520 - maeOverFscore_keras: 1.5632 - fscore_keras: 0.8193 - val_loss: 65.8270 - val_maeOverFscore_keras: 1.4880 - val_fscore_keras: 0.7381\n",
            "Epoch 11/50\n",
            "993/993 [==============================] - 362s 365ms/step - loss: 0.1515 - maeOverFscore_keras: 1.5563 - fscore_keras: 0.8206 - val_loss: 65.8260 - val_maeOverFscore_keras: 1.4076 - val_fscore_keras: 0.7632\n",
            "Epoch 12/50\n",
            "993/993 [==============================] - 364s 367ms/step - loss: 0.1515 - maeOverFscore_keras: 1.5527 - fscore_keras: 0.8212 - val_loss: 65.8254 - val_maeOverFscore_keras: 1.3722 - val_fscore_keras: 0.7703\n",
            "Epoch 13/50\n",
            "993/993 [==============================] - 363s 365ms/step - loss: 0.1511 - maeOverFscore_keras: 1.5480 - fscore_keras: 0.8218 - val_loss: 65.8258 - val_maeOverFscore_keras: 1.3995 - val_fscore_keras: 0.7613\n",
            "Epoch 14/50\n",
            "993/993 [==============================] - 363s 365ms/step - loss: 0.1507 - maeOverFscore_keras: 1.5445 - fscore_keras: 0.8228 - val_loss: 65.8254 - val_maeOverFscore_keras: 1.3960 - val_fscore_keras: 0.7628\n",
            "Epoch 15/50\n",
            "993/993 [==============================] - 362s 365ms/step - loss: 0.1505 - maeOverFscore_keras: 1.5392 - fscore_keras: 0.8232 - val_loss: 65.8263 - val_maeOverFscore_keras: 1.4322 - val_fscore_keras: 0.7569\n",
            "Epoch 16/50\n",
            "993/993 [==============================] - 362s 365ms/step - loss: 0.1502 - maeOverFscore_keras: 1.5374 - fscore_keras: 0.8234 - val_loss: 65.8256 - val_maeOverFscore_keras: 1.4041 - val_fscore_keras: 0.7637\n",
            "Epoch 17/50\n",
            "993/993 [==============================] - 360s 363ms/step - loss: 0.1500 - maeOverFscore_keras: 1.5331 - fscore_keras: 0.8241 - val_loss: 65.8262 - val_maeOverFscore_keras: 1.4014 - val_fscore_keras: 0.7685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoowuSxyZgLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 모델 저장하기\n",
        "cnt = 0\n",
        "for model in models:\n",
        "    cnt += 1\n",
        "    model.save(f'/content/drive/My Drive/2020 Kaggle Study/model/model{cnt}.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjmLe8t7j8cN",
        "colab_type": "text"
      },
      "source": [
        "## Precipatation GMI -> DPR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyTSFuEGkEd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dr = [(-1, -1), (-1, 0), (-1, 1),\n",
        "      (0, -1), (0, 0), (0, 1),\n",
        "      (1, -1), (1, 0), (1, 1)]\n",
        "\n",
        "def get_dist(p1, p2):  # p1, p2: shape=(-1, 2).\n",
        "    x1, y1 = np.deg2rad(p1[:,0]), np.deg2rad(p1[:,1])\n",
        "    x2, y2 = np.deg2rad(p2[:,0]), np.deg2rad(p2[:,1])\n",
        "    dlon = x2 - x1\n",
        "    dlat = y2 - y1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(y1) * np.cos(y2) * np.sin(dlon/2)**2 \n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))    \n",
        "    return 6373.0 * c  # km, shape=(-1).\n",
        "\n",
        "# value: (40, 40, -1)\n",
        "# ori_ll, tgt_ll: (40, 40, 2)\n",
        "def compen_ll(value, ori_ll, tgt_ll):  # ori_ll에서의 value를 tgt_ll에 대한 값으로 바꿈\n",
        "    ret = np.empty_like(value)\n",
        "    n, m = value.shape[0], value.shape[1]\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            nears = []  # (row, col, value)\n",
        "            for k in range(9):\n",
        "                ii = i + dr[k][0]\n",
        "                jj = j + dr[k][1]\n",
        "                if ii >= 0 and ii < n and jj >= 0 and jj < m:\n",
        "                    nears.append((ori_ll[ii, jj][0], ori_ll[ii, jj][1],\n",
        "                                  tgt_ll[i, j][0], tgt_ll[i, j][1],\n",
        "                                  value[ii, jj]))\n",
        "            nears = np.array(nears)  # shape=(-1, 5)\n",
        "            dists = get_dist(nears[:, 0:2], nears[:, 2:4]).reshape(-1, 1)\n",
        "            values = nears[:, 4].reshape(-1, 1)\n",
        "            nears = np.concatenate((dists, values), 1)\n",
        "            nears = nears[np.argsort(nears[:, 0])]  # sort by dist\n",
        "            nears = nears[:2, :]  # 가까운 점 2개만 고려\n",
        "            \n",
        "            weights = 1 / (nears[:, 0] ** 2 + sys.float_info.epsilon)\n",
        "            weighted_sum = (weights * nears[:, 1]).sum()\n",
        "            ret[i, j] = weighted_sum / weights.sum()\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSTjD9TqqRXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Process, Manager\n",
        "\n",
        "def proc_func(splitted, dpr_preci, proc_id):\n",
        "    part = splitted[proc_id]\n",
        "    arr = np.empty_like(part[:, :, :, 14])  # shape=(-1, 40, 40)\n",
        "    for i in range(part.shape[0]):\n",
        "        arr[i, :, :] = compen_ll(part[i, :, :, 14], part[i, :, :, 10:12], part[i, :, :, 12:14])\n",
        "    dpr_preci[proc_id] = arr\n",
        "\n",
        "def gmi2dpr(test, gmi_preci):\n",
        "    n_procs = 8\n",
        "    procs = []\n",
        "    manager = Manager()\n",
        "    dpr_preci = manager.list([None] * n_procs)\n",
        "\n",
        "    data = np.concatenate((test, gmi_preci), axis=3)\n",
        "    n_imgs = data.shape[0]  # split data into n_procs arrays\n",
        "    splitted = np.split(data, np.arange(n_imgs // n_procs + n_imgs % n_procs, n_imgs, n_imgs // n_procs))\n",
        "\n",
        "    for proc_id in range(n_procs):\n",
        "        proc = Process(target=proc_func, args=(splitted, dpr_preci, proc_id))\n",
        "        proc.start()\n",
        "        procs.append(proc)\n",
        "\n",
        "    for proc in procs:\n",
        "        proc.join()\n",
        "\n",
        "    dpr_preci = np.concatenate(dpr_preci)\n",
        "    return dpr_preci"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaiM97kupa2Z",
        "colab_type": "text"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp50F1SKpdS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "bca012eb-a4d0-4c62-cfe9-82efd0f170d2"
      },
      "source": [
        "x_val, y_val = val[:, :, :, :10], val[:, :, :, -1]\n",
        "\n",
        "preds = []\n",
        "for model in models:\n",
        "    pred = model.predict(x_val)\n",
        "    pred = gmi2dpr(val[:, :, :, :-1], pred)\n",
        "    preds.append(pred)\n",
        "    val_score = maeOverFscore(y_val, pred)\n",
        "    print(val_score)\n",
        "final_pred = sum(preds) / len(preds)\n",
        "final_val_score = maeOverFscore(y_val, final_pred)\n",
        "final_val_score"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5511447334556319\n",
            "1.5412712112244045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.524990308944763"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2xM7q7FpIttP"
      },
      "source": [
        "## submission 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG9A32a6qyyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = preprocess(test)\n",
        "x_test = test[:, :, :, :10]\n",
        "\n",
        "preds = []\n",
        "for model in models:\n",
        "    pred = model.predict(x_test)\n",
        "    pred = gmi2dpr(test, pred)\n",
        "    preds.append(pred)\n",
        "final_pred = sum(preds) / len(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BaAuaIqhh_z3",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('/content/drive/My Drive/2020 Kaggle Study/data/sample_submission.csv')\n",
        "submission.iloc[:,1:] = final_pred.reshape(-1, 1600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fBTzEKnh_0B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "73ddc4c8-6e3f-487a-a72c-67916cf4bf53"
      },
      "source": [
        "# 제출 파일 저장하기\n",
        "submission.to_csv('/content/drive/My Drive/2020 Kaggle Study/submission/submission2208.csv', index=False)\n",
        "submission"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>px_1</th>\n",
              "      <th>px_2</th>\n",
              "      <th>px_3</th>\n",
              "      <th>px_4</th>\n",
              "      <th>px_5</th>\n",
              "      <th>px_6</th>\n",
              "      <th>px_7</th>\n",
              "      <th>px_8</th>\n",
              "      <th>px_9</th>\n",
              "      <th>px_10</th>\n",
              "      <th>px_11</th>\n",
              "      <th>px_12</th>\n",
              "      <th>px_13</th>\n",
              "      <th>px_14</th>\n",
              "      <th>px_15</th>\n",
              "      <th>px_16</th>\n",
              "      <th>px_17</th>\n",
              "      <th>px_18</th>\n",
              "      <th>px_19</th>\n",
              "      <th>px_20</th>\n",
              "      <th>px_21</th>\n",
              "      <th>px_22</th>\n",
              "      <th>px_23</th>\n",
              "      <th>px_24</th>\n",
              "      <th>px_25</th>\n",
              "      <th>px_26</th>\n",
              "      <th>px_27</th>\n",
              "      <th>px_28</th>\n",
              "      <th>px_29</th>\n",
              "      <th>px_30</th>\n",
              "      <th>px_31</th>\n",
              "      <th>px_32</th>\n",
              "      <th>px_33</th>\n",
              "      <th>px_34</th>\n",
              "      <th>px_35</th>\n",
              "      <th>px_36</th>\n",
              "      <th>px_37</th>\n",
              "      <th>px_38</th>\n",
              "      <th>px_39</th>\n",
              "      <th>...</th>\n",
              "      <th>px_1561</th>\n",
              "      <th>px_1562</th>\n",
              "      <th>px_1563</th>\n",
              "      <th>px_1564</th>\n",
              "      <th>px_1565</th>\n",
              "      <th>px_1566</th>\n",
              "      <th>px_1567</th>\n",
              "      <th>px_1568</th>\n",
              "      <th>px_1569</th>\n",
              "      <th>px_1570</th>\n",
              "      <th>px_1571</th>\n",
              "      <th>px_1572</th>\n",
              "      <th>px_1573</th>\n",
              "      <th>px_1574</th>\n",
              "      <th>px_1575</th>\n",
              "      <th>px_1576</th>\n",
              "      <th>px_1577</th>\n",
              "      <th>px_1578</th>\n",
              "      <th>px_1579</th>\n",
              "      <th>px_1580</th>\n",
              "      <th>px_1581</th>\n",
              "      <th>px_1582</th>\n",
              "      <th>px_1583</th>\n",
              "      <th>px_1584</th>\n",
              "      <th>px_1585</th>\n",
              "      <th>px_1586</th>\n",
              "      <th>px_1587</th>\n",
              "      <th>px_1588</th>\n",
              "      <th>px_1589</th>\n",
              "      <th>px_1590</th>\n",
              "      <th>px_1591</th>\n",
              "      <th>px_1592</th>\n",
              "      <th>px_1593</th>\n",
              "      <th>px_1594</th>\n",
              "      <th>px_1595</th>\n",
              "      <th>px_1596</th>\n",
              "      <th>px_1597</th>\n",
              "      <th>px_1598</th>\n",
              "      <th>px_1599</th>\n",
              "      <th>px_1600</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>029858_01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.41459</td>\n",
              "      <td>0.067801</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>029858_02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.238550</td>\n",
              "      <td>0.094530</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>029858_03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024064</td>\n",
              "      <td>0.20049</td>\n",
              "      <td>0.055753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>029858_05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.747964</td>\n",
              "      <td>0.963497</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.671560</td>\n",
              "      <td>2.434068</td>\n",
              "      <td>3.515583</td>\n",
              "      <td>1.120019</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>029858_07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.137578</td>\n",
              "      <td>1.204139</td>\n",
              "      <td>1.328896</td>\n",
              "      <td>2.122036</td>\n",
              "      <td>2.950738</td>\n",
              "      <td>2.690796</td>\n",
              "      <td>1.860008</td>\n",
              "      <td>0.911722</td>\n",
              "      <td>0.788274</td>\n",
              "      <td>1.185023</td>\n",
              "      <td>1.916835</td>\n",
              "      <td>3.211698</td>\n",
              "      <td>3.852836</td>\n",
              "      <td>3.73971</td>\n",
              "      <td>4.879528</td>\n",
              "      <td>7.466562</td>\n",
              "      <td>12.325948</td>\n",
              "      <td>16.798768</td>\n",
              "      <td>19.02841</td>\n",
              "      <td>18.677109</td>\n",
              "      <td>13.233391</td>\n",
              "      <td>6.696187</td>\n",
              "      <td>9.312072</td>\n",
              "      <td>11.625813</td>\n",
              "      <td>5.601132</td>\n",
              "      <td>1.787307</td>\n",
              "      <td>0.737992</td>\n",
              "      <td>0.230536</td>\n",
              "      <td>0.281938</td>\n",
              "      <td>0.654964</td>\n",
              "      <td>1.252712</td>\n",
              "      <td>1.654624</td>\n",
              "      <td>1.519088</td>\n",
              "      <td>1.149444</td>\n",
              "      <td>1.241715</td>\n",
              "      <td>2.216405</td>\n",
              "      <td>3.49056</td>\n",
              "      <td>3.556925</td>\n",
              "      <td>2.379899</td>\n",
              "      <td>1.431028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2411</th>\n",
              "      <td>031287_08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2412</th>\n",
              "      <td>031288_01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2413</th>\n",
              "      <td>031288_02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>031288_08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>031288_11</td>\n",
              "      <td>0.521937</td>\n",
              "      <td>0.522842</td>\n",
              "      <td>0.518503</td>\n",
              "      <td>0.405164</td>\n",
              "      <td>0.374618</td>\n",
              "      <td>0.461981</td>\n",
              "      <td>0.214253</td>\n",
              "      <td>0.034803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2416 rows × 1601 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id      px_1      px_2  ...   px_1598   px_1599   px_1600\n",
              "0     029858_01  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "1     029858_02  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "2     029858_03  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "3     029858_05  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "4     029858_07  0.000000  0.000000  ...  3.556925  2.379899  1.431028\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "2411  031287_08  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "2412  031288_01  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "2413  031288_02  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "2414  031288_08  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "2415  031288_11  0.521937  0.522842  ...  0.000000  0.000000  0.000000\n",
              "\n",
              "[2416 rows x 1601 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}