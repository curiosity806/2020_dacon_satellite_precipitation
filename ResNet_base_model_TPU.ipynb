{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_base_model_TPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curiosity806/2020_dacon_satellite_precipitation/blob/augment8%2Fresnet-single/ResNet_base_model_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi-MWY4HOblX",
        "colab_type": "code",
        "outputId": "acbb8506-74f2-4d3c-81ef-786c8c21be3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pj84NcY6oGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/2020 Kaggle Study/data/Copy of train.npy' train.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6La-zpczGzY",
        "colab_type": "code",
        "outputId": "cc594ac9-4b5e-40a6-cadd-71b70b69f6b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, MaxPooling2D, BatchNormalization, Activation, concatenate, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "import warnings\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from scipy import stats\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# style 설정\n",
        "plt.style.use('dark_background')\n",
        "plt.style.use('seaborn-colorblind')\n",
        "\n",
        "# 재생산성을 위해 시드 고정\n",
        "np.random.seed(7)\n",
        "random.seed(7)\n",
        "tf.random.set_seed(7)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pUOc4bq-IrZ",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 받아오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36olRM2r6rBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train = np.load('train.npy')\n",
        "train = np.load('train.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYZYG3G-Itsk"
      },
      "source": [
        "# 데이터 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaRH52X7i4jR",
        "colab_type": "code",
        "outputId": "b1672c8f-17cb-46e6-e42a-268ec29b60a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76345, 40, 40, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmLU5Ozj0xLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqQKaS6o537l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cutoff(data):\n",
        "    index = 0\n",
        "    rain_index = []\n",
        "    for file in data:\n",
        "        target= file[:,:,-1].reshape(40,40,1)\n",
        "        cutoff_labels = np.where(target < 0, 0, target)\n",
        "        if (cutoff_labels > 0).sum() < 50:\n",
        "            index = index + 1\n",
        "            continue\n",
        "        rain_index.append(index)\n",
        "        index = index + 1\n",
        "    return data[rain_index], rain_index\n",
        "\n",
        "def re_landtype(data):\n",
        "    rain = data[:,:,:,9].reshape(-1)\n",
        "    rain = rain//100\n",
        "    #data[data[:,:,:,9] == 0] = 0 #Ocean\n",
        "    rain[rain == 1] = 1 #land\n",
        "    rain[rain == 2] = 0.5 #costal\n",
        "    rain[rain == 3] = 0.2 #in land water\n",
        "    data[:,:,:,9] = rain.reshape(-1,40,40)\n",
        "    return data\n",
        "    \n",
        "def select_ch(data,ch_list = [0,1,2,3,4,5,6,7,8,9,14]):#9: land_type, 14: precipitation\n",
        "    return(data[:,:,:,ch_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzjyEoEa7pMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = select_ch(train)\n",
        "train, rain_index = cutoff(train)\n",
        "train = re_landtype(train)\n",
        "\n",
        "#train = tf.convert_to_tensor(train, dtype=np.float32)\n",
        "#train = train.numpy()\n",
        "#gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARExxyqONfIK",
        "colab_type": "text"
      },
      "source": [
        "#모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz008iV85Oi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    inputs=Input((40,40,10))\n",
        "    ###cnn\n",
        "    bn=BatchNormalization()(inputs)\n",
        "    conv0=Conv2D(256, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "    \n",
        "    bn=BatchNormalization()(conv0)\n",
        "    conv=Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
        "    concat=concatenate([conv0, conv], axis=3)\n",
        "    \n",
        "    bn=BatchNormalization()(concat)\n",
        "    conv=Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
        "    concat=concatenate([concat, conv], axis=3)\n",
        "        \n",
        "    for i in range(5):\n",
        "        bn=BatchNormalization()(concat)\n",
        "        conv=Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
        "        concat=concatenate([concat, conv], axis=3)\n",
        "    \n",
        "    bn=BatchNormalization()(concat)\n",
        "    outputs=Conv2D(1, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "    \n",
        "    model=Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_NhbS4s09p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def mae(y_true, y_pred) :\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    over_threshold = y_true >= 0.1\n",
        "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    remove_NAs = y_true >= 0\n",
        "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
        "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
        "    return(f1_score(y_true, y_pred))\n",
        "\n",
        "def maeOverFscore(y_true, y_pred):\n",
        "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
        "\n",
        "def fscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
        "    return score\n",
        "\n",
        "def maeOverFscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nWrybUnXIts7"
      },
      "source": [
        "## 데이터 제네레이터 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYdKSO0P5y5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred):\n",
        "    y_true = K.ones_like(y_true) \n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    all_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    \n",
        "    recall = true_positives / (all_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    y_true = K.ones_like(y_true) \n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    \n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rZfgGM23wi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEu-nng86QyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Metric은 tf.keras.metrics.Metric이거 상속받아서 custom할 것\n",
        "#아직 만드는 중....\n",
        "\n",
        "class maeOverFscore(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='multi_label_metric'):\n",
        "        super(maeOverFscore, self).__init__(name=name)\n",
        "        # 계산에 필요한 변수들 선언\n",
        "        self.maeOverFscore = self.add_weight(name='maeOverFscore', initializer='zeros')\n",
        "        #self.mae = self.add_weight(name='mae', initializer='zeros')\n",
        "        #self.Fscore = self.add_weight(name='Fscore', initializer='zeros')\n",
        "        \n",
        "    def update_state(self, y, pred):\n",
        "    \t'''metric 계산'''\n",
        "        TP = tf.count_nonzero(pred * y)\n",
        "        TN = tf.count_nonzero((pred - 1) * (y - 1))\n",
        "        FP = tf.count_nonzero(pred * (y - 1))\n",
        "        FN = tf.count_nonzero((pred - 1) * y)\n",
        "\n",
        "        precision = tf.divide(TP, TP + FP)\n",
        "        precision = tf.divide(TP, TP + FN)\n",
        "        Fscore =  tf.divide(2 * precision * recall, (precision + recall))\n",
        "        \n",
        "        threshold = 0.1\n",
        "\n",
        "    \t# prediction과 label이 완전히 일치하는 경우 계산\n",
        "        correct_pred = tf.math.equal(tf.round(y), tf.round(pred))\n",
        "        correct_pred = tf.reduce_sum(tf.cast(tf.reduce_all(correct_pred, 1), tf.float32))\n",
        "        \n",
        "    \t# 변수에 더해줌\n",
        "        self.corr.assign_add(correct_pred)  # 지금까지 y, prediction 완전 일치하는 횟수\n",
        "        self.example_num.assign_add(y.shape[0])  # 전체 (y, prediction) 쌍의 수\n",
        "    \n",
        "    def result(self):\n",
        "    \t'''지금까지 계산된 metric 반환'''\n",
        "        return self.corr / self.example_num\n",
        "    \n",
        "    def reset_states(self):\n",
        "    \t'''변수 초기화'''\n",
        "        self.corr.assign(0)\n",
        "        self.example_num.assign(0)\n",
        "\n",
        "class maeOverFscore(tf.keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self, name='maeOverFscore', **kwargs):\n",
        "      super(maeOverFscore, self).__init__(name=name, **kwargs)\n",
        "      self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
        "      self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "      y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
        "      values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n",
        "      values = tf.cast(values, 'float32')\n",
        "      if sample_weight is not None:\n",
        "        sample_weight = tf.cast(sample_weight, 'float32')\n",
        "        values = tf.multiply(values, sample_weight)\n",
        "      self.true_positives.assign_add(tf.reduce_sum(values))\n",
        "\n",
        "    def result(self):\n",
        "      return self.true_positives\n",
        "\n",
        "    def reset_states(self):\n",
        "      # The state of the metric will be reset at the start of each epoch.\n",
        "      self.true_positives.assign(0.)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7bNrP0L6Qvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIavrvF-6Qtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyp-tdu1iNkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TPU설정 안될때 실행\n",
        "error = False\n",
        "if error:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FsTGyUIleijx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "outputId": "8a831f82-e4ab-4d1d-f0bf-4a4565038fb1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.model_selection import KFold\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def rotate90(x,y):\n",
        "    return tf.image.rot90(x), tf.image.rot90(y)\n",
        "\n",
        "def transpose(x,y):\n",
        "    return tf.image.transpose(x), tf.image.transpose(y)\n",
        "\n",
        "\n",
        "def train_model(x_data, y_data, k, s):\n",
        "    k_fold = KFold(n_splits=k, shuffle=True, random_state=7777)\n",
        "    model_number = 0\n",
        "    for train_idx, val_idx in k_fold.split(x_data):\n",
        "        if model_number == s:\n",
        "            x_train, y_train = x_data[train_idx], y_data[train_idx]\n",
        "            x_val, y_val = x_data[val_idx], y_data[val_idx]\n",
        "            \n",
        "            # TPU에 모델 올리기\n",
        "            resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "            tf.config.experimental_connect_to_cluster(resolver)\n",
        "            # This is the TPU initialization code that has to be at the beginning.\n",
        "            tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "            with strategy.scope():\n",
        "                model = create_model()\n",
        "                model.compile(optimizer = 'adam',loss = 'mae'#,\n",
        "                #metrics=[maeOverFscore,fscore]\n",
        "                )\n",
        "\n",
        "                callbacks_list = [\n",
        "                    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                        monitor='val_loss',\n",
        "                        patience=3,\n",
        "                        factor=0.8\n",
        "                    ),\n",
        "                    tf.keras.callbacks.ModelCheckpoint(\n",
        "                        filepath = '/content/drive/My Drive/2020 Kaggle Study/deagwon/best_model'+str(model_number)+'.h5',\n",
        "                        monitor='val_fscore',\n",
        "                        save_best_only=True\n",
        "                    )\n",
        "                ]\n",
        "                \n",
        "\n",
        "            batch_size = 128\n",
        "\n",
        "            # batch_dataset 만들기\n",
        "            non_augmented_train_batches = (\n",
        "                tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "                .repeat()\n",
        "                .cache()\n",
        "                .batch(batch_size = batch_size, drop_remainder=True)\n",
        "                .map(rotate90 , num_parallel_calls=AUTO)\n",
        "            )\n",
        "            # augmentation_batches 만들기\n",
        "            rotate90_train_batches = non_augmented_train_batches.map(rotate90 , num_parallel_calls=AUTO)\n",
        "            rotate180_train_batches = rotate90_train_batches.map(rotate90 , num_parallel_calls=AUTO)\n",
        "            rotate270_train_batches = rotate180_train_batches.map(rotate90 , num_parallel_calls=AUTO)\n",
        "            train_transpose_batches = non_augmented_train_batches.map(transpose , num_parallel_calls=AUTO)\n",
        "            rotate90_transpose_batches = rotate90_train_batches.map(transpose , num_parallel_calls=AUTO)\n",
        "            rotate180_transpose_batches = rotate180_train_batches.map(transpose , num_parallel_calls=AUTO)\n",
        "            rotate270_transpose_batches = rotate270_train_batches.map(transpose , num_parallel_calls=AUTO)\n",
        "            \n",
        "            # augmentation batch 합쳐서 train batches 만들기\n",
        "            train_batches = non_augmented_train_batches.concatenate(rotate90_train_batches)\n",
        "            train_batches = train_batches.concatenate(rotate180_train_batches)\n",
        "            train_batches = train_batches.concatenate(rotate270_train_batches)\n",
        "            train_batches = train_batches.concatenate(train_transpose_batches)\n",
        "            train_batches = train_batches.concatenate(rotate180_transpose_batches)\n",
        "            train_batches = train_batches.concatenate(rotate270_transpose_batches)\n",
        "\n",
        "            #agumentation batch shuffle \n",
        "            train_batches = train_batches.shuffle(buffer_size = batch_size * 8)\n",
        "            train_batches = train_batches.prefetch(AUTOTUNE)\n",
        "\n",
        "\n",
        "            model.fit(train_batches, epochs=1,\n",
        "                    steps_per_epoch = len(x_train)*8 // batch_size,\n",
        "                    validation_data=(x_val, y_val))#, callbacks=callbacks_list)\n",
        "\n",
        "            model.save(f'/content/drive/My Drive/2020 Kaggle Study/deagwon/model_trainonly_{model_number}.h5')\n",
        "            break##### 일단은 한 폴드만 학습\n",
        "        model_number+=1\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "k = 5\n",
        "models = []\n",
        "train_model(train[:,:,:,:-1], train[:,:,:,-1].reshape(-1,40,40,1), k=k, s=4)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.61.27.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.61.27.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.61.27.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.61.27.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1538/1538 [==============================] - 94s 61ms/step - loss: 5.0219 - val_loss: 4.7552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSNAiNaT8iYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XsjsawsGh_zs",
        "colab": {}
      },
      "source": [
        "# 훈련에서 사용하는 0~8번 채널, ladtype 만을 뽑아서 X_test에 저장하기\n",
        "test_submit = np.load('/content/drive/My Drive/2020 Kaggle Study/data/test.npy')\n",
        "test_submit = test_submit[:,:,:,:10]\n",
        "del test_submit\n",
        "gc.collect()\n",
        "pred = model.predict(test_submit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2xM7q7FpIttP"
      },
      "source": [
        "## submission 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BaAuaIqhh_z3",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('/content/drive/My Drive/2020 Kaggle Study/data/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r3sFI91Gh_z8",
        "colab": {}
      },
      "source": [
        "submission.iloc[:,1:] = pred.reshape(-1, 1600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bPPRCvO_h_z_",
        "colab": {}
      },
      "source": [
        "submission.to_csv('Dacon_landtype.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fBTzEKnh_0B",
        "colab": {}
      },
      "source": [
        "# 제출파일 구글 드라이브에 올리기\n",
        "!cp Dacon_landtype.csv '/content/drive/My Drive/2020 Kaggle Study/submission'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}