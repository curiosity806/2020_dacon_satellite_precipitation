{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "normalization__augment_modeling",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curiosity806/2020_dacon_satellite_precipitation/blob/deagwon/normalization__augment_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi-MWY4HOblX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1dd0d761-ccdc-427c-ce3b-e101c466911c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6La-zpczGzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c29df196-0b64-4da9-c189-b7754961ff7f"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Conv2DTranspose, MaxPooling2D, BatchNormalization, Activation, concatenate, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "import warnings\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from scipy import stats\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_5kuij4XMPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# style 설정\n",
        "plt.style.use('dark_background')\n",
        "plt.style.use('seaborn-colorblind')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihaRksAgzLvo",
        "colab_type": "code",
        "outputId": "cd71caeb-68de-4ec9-e83a-5e8ed17aef6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PePNDtUzKlW3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pUOc4bq-IrZ",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 받아오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKjP-Uobze5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 재생산성을 위해 시드 고정\n",
        "np.random.seed(7)\n",
        "random.seed(7)\n",
        "tf.random.set_seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYZYG3G-Itsk"
      },
      "source": [
        "# 모델만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAFbyVFrgxfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_normalization = np.load('/content/drive/My Drive/2020 Kaggle Study/data/part_normalization/part_normalization_onlyrain.npy')\n",
        "train_normalization = np.load('train_normalization.npy')\n",
        "\n",
        "\n",
        "index = 0\n",
        "rain_index = []\n",
        "for file in train_normalization:\n",
        "    target= file[:,:,-1].reshape(40,40,1)\n",
        "    cutoff_labels = np.where(target < 0, 0, target)\n",
        "    if (cutoff_labels > 0).sum() < 50:\n",
        "        index = index + 1\n",
        "        continue\n",
        "    rain_index.append(index)\n",
        "    index = index + 1\n",
        "#train_normalization = train_normalization[rain_index]\n",
        "#np.save('/content/drive/My Drive/2020 Kaggle Study/data/part_normalization/part_normalization_onlyrain.npy', train_normalization)\n",
        "#train_normalization.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suJx4607ywzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_normalization = train_normalization[rain_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsAjHMuZhK-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_generator(train):\n",
        "    rotate = np.zeros([train.shape[0]*8,train.shape[1],train.shape[2],train.shape[3]])\n",
        "    ch_num = train.shape[3]\n",
        "    train_len = train.shape[0]\n",
        "    rotate[:train_len,:,:,:] = train\n",
        "    del train\n",
        "    rotate[train_len : train_len * 2,:,:,:] = np.rot90(rotate[:train_len,:,:,:], axes = (1,2))\n",
        "    rotate[train_len * 2 : train_len * 3,:,:,:] = np.rot90(rotate[train_len : train_len * 2,:,:,:], axes = (1,2))\n",
        "    rotate[train_len * 3 : train_len * 4,:,:,:] = np.rot90(rotate[train_len * 2 : train_len * 3,:,:,:], axes = (1,2))\n",
        "    rotate[train_len * 4 :,:,:,:] = np.transpose(rotate[: train_len * 4,:,:,:], axes = (0,1,2,3))\n",
        "    return rotate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz008iV85Oi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    inputs=Input((40,40,10))\n",
        "    \n",
        "    bn=BatchNormalization()(inputs)\n",
        "    conv0=Conv2D(256, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "    \n",
        "    bn=BatchNormalization()(conv0)\n",
        "    conv=Conv2D(128, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
        "    concat=concatenate([conv0, conv], axis=3)\n",
        "    \n",
        "    bn=BatchNormalization()(concat)\n",
        "    conv=Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
        "    concat=concatenate([concat, conv], axis=3)\n",
        "        \n",
        "    for i in range(5):\n",
        "        bn=BatchNormalization()(concat)\n",
        "        conv=Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(bn)\n",
        "        concat=concatenate([concat, conv], axis=3)\n",
        "    \n",
        "    bn=BatchNormalization()(concat)\n",
        "    outputs=Conv2D(1, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "    \n",
        "    model=Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqMt4p1N09nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#model = Model(input_layer, output_layer)\n",
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_NhbS4s09p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def mae(y_true, y_pred) :\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    over_threshold = y_true >= 0.1\n",
        "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    remove_NAs = y_true >= 0\n",
        "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
        "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
        "    return(f1_score(y_true, y_pred))\n",
        "\n",
        "def maeOverFscore(y_true, y_pred):\n",
        "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
        "\n",
        "def fscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
        "    return score\n",
        "\n",
        "def maeOverFscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv7Hk_LM1DNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nWrybUnXIts7"
      },
      "source": [
        "## 데이터 제네레이터 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSQ-XoTIMsD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GMI좌표로 보정된 데이터\n",
        "gmi_pre = np.load('/content/drive/My Drive/2020 Kaggle Study/data/gmi_preci_32bits.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-rAnAGAXEk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_generator(train):\n",
        "    rotate = np.zeros([train.shape[0]*8,train.shape[1],train.shape[2],train.shape[3]])\n",
        "    ch_num = train.shape[3]\n",
        "    train_len = train.shape[0]\n",
        "    rotate[:train_len,:,:,:] = train\n",
        "    del train\n",
        "    rotate[train_len : train_len * 2,:,:,:] = np.rot90(rotate[:train_len,:,:,:], axes = (1,2))\n",
        "    rotate[train_len * 2 : train_len * 3,:,:,:] = np.rot90(rotate[train_len : train_len * 2,:,:,:], axes = (1,2))\n",
        "    rotate[train_len * 3 : train_len * 4,:,:,:] = np.rot90(rotate[train_len * 2 : train_len * 3,:,:,:], axes = (1,2))\n",
        "    rotate[train_len * 4 :,:,:,:] = np.transpose(rotate[: train_len * 4,:,:,:], axes = (0,1,2,3))\n",
        "    return rotate\n",
        "\n",
        "class MultiOutputDataGenerator(tf.keras.preprocessing.image.ImageDataGenerator):\n",
        "    def flow(self,\n",
        "             x,\n",
        "             y,\n",
        "             batch_size=None,\n",
        "             shuffle=True,\n",
        "             sample_weight=None,\n",
        "             seed=None,\n",
        "             save_to_dir=None,\n",
        "             save_prefix='',\n",
        "             save_format='png',\n",
        "             subset=None):\n",
        "\n",
        "        for flowx, flowy in super().flow(x,y, batch_size= batch_size, shuffle = shuffle):\n",
        "            flowx = augment_generator(flowx)\n",
        "            flowy = augment_generator(flowy)\n",
        "            yield (flowx, flowy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEDseZZIzg66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd0bbd96-e4eb-4b0f-dbe8-4d5be95f0f2e"
      },
      "source": [
        "train_normalization.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44939, 40, 40, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSK1Hk1Z16ZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "def train_model(x_data, y_data, k, s):\n",
        "    \n",
        "    k_fold = KFold(n_splits=k, shuffle=True, random_state=7777)\n",
        "    \n",
        "    model_number = 0\n",
        "    for train_idx, val_idx in k_fold.split(x_data):\n",
        "        if model_number == s:\n",
        "            x_train, y_train = x_data[train_idx], y_data[train_idx]\n",
        "            x_val, y_val = x_data[val_idx], y_data[val_idx]\n",
        "\n",
        "            # 데이터를 부풀릴시 많은 양의 메모리가 필요\n",
        "            #x_train, y_train = data_generator(x_train, y_train)\n",
        "\n",
        "            model = create_model()\n",
        "\n",
        "            model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[maeOverFscore_keras, fscore_keras])\n",
        "\n",
        "            callbacks_list = [\n",
        "                tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                    monitor='val_loss',\n",
        "                    patience=3,\n",
        "                    factor=0.8\n",
        "                ),\n",
        "\n",
        "                tf.keras.callbacks.ModelCheckpoint(\n",
        "                    filepath = 'models/model'+str(model_number)+'.h5',\n",
        "                    monitor='val_score',\n",
        "                    save_best_only=True\n",
        "                )\n",
        "            ]\n",
        "            datagen = MultiOutputDataGenerator()\n",
        "            datagen.fit(x_train)\n",
        "\n",
        "            model.fit(datagen.flow(x_train, y_train, batch_size=16), epochs=50,  validation_data=(x_val, y_val), callbacks=callbacks_list)\n",
        "        \n",
        "        model_number+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-2Q9-tuUviM",
        "colab_type": "code",
        "outputId": "55ad486d-da0d-432c-b825-9bd66b7834a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_normalization[:,:,:,-1].reshape(-1,40,40,1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30760, 40, 40, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcJ7pOZA71q-",
        "colab_type": "code",
        "outputId": "8b4173a1-96a9-4918-fa0d-1d25e8a62690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_normalization.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30760, 40, 40, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgqhCsNBZpm0",
        "colab_type": "code",
        "outputId": "9460be26-0565-4582-ef9d-362da63ee00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model, Model\n",
        "k = 5\n",
        "models = []\n",
        "\n",
        "train_model(train_normalization[:,:,:,:-1], train_normalization[:,:,:,-1].reshape(-1,40,40,1), k=k, s=4)\n",
        "\n",
        "for n in range(k):\n",
        "    model = load_model('/content/drive/My Drive/2020 Kaggle Study/deagwon/model'+str(n)+'.h5', custom_objects = {'score':score,'fscore_keras':fscore_keras})\n",
        "    models.append(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "    431/Unknown - 145s 336ms/step - loss: 4.3946 - maeOverFscore_keras: 3.0396 - fscore_keras: 0.5841"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qg-RmDqpVq3",
        "colab_type": "text"
      },
      "source": [
        "## submission 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvxpahHEOEJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dr = [(-1, -1), (-1, 0), (-1, 1),\n",
        "      (0, -1), (0, 0), (0, 1),\n",
        "      (1, -1), (1, 0), (1, 1)]\n",
        "\n",
        "# p1, p2: shape=(-1, 2).\n",
        "def get_dist(p1, p2):\n",
        "    x1 = np.deg2rad(p1[:,0])\n",
        "    y1 = np.deg2rad(p1[:,1])\n",
        "    x2 = np.deg2rad(p2[:,0])\n",
        "    y2 = np.deg2rad(p2[:,1])\n",
        "    dlon = x2 - x1\n",
        "    dlat = y2 - y1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(y1) * np.cos(y2) * np.sin(dlon/2)**2 \n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))    \n",
        "    return 6373.0 * c  # km, shape=(-1).\n",
        "\n",
        "# ori_ll에서의 value 값을 tgt_ll에 대한 값으로 바꾼다.\n",
        "# value: (40, 40, -1)\n",
        "# ori_ll, tgt_ll: (40, 40, 2)\n",
        "# ori_ll: value에 대응되는 원래 latitude, longitude.\n",
        "# tgt_ll: 변환되는 값에 대응되는 latitude, longitude.\n",
        "def compen_ll(value, ori_ll, tgt_ll):\n",
        "    ret = np.empty_like(value)\n",
        "\n",
        "    n = value.shape[0]\n",
        "    m = value.shape[1]\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            nears = []  # (row, col, value)\n",
        "            for k in range(9):\n",
        "                ii = i + dr[k][0]\n",
        "                jj = j + dr[k][1]\n",
        "                if ii >= 0 and ii < n and jj >= 0 and jj < m:\n",
        "                    nears.append((ori_ll[ii, jj][0], ori_ll[ii, jj][1],\n",
        "                                  tgt_ll[i, j][0], tgt_ll[i, j][1],\n",
        "                                  value[ii, jj]))\n",
        "\n",
        "            nears = np.array(nears)  # shape=(-1, 5)\n",
        "            dists = get_dist(nears[:, 0:2], nears[:, 2:4]).reshape(-1, 1)\n",
        "            values = nears[:, 4].reshape(-1, 1)\n",
        "            nears = np.concatenate((dists, values), 1)\n",
        "            nears = nears[np.argsort(nears[:, 0])]  # sort by dist\n",
        "\n",
        "            weights = 1 / (nears[:, 0] ** 2 + sys.float_info.epsilon)\n",
        "            weighted_sum = (weights * nears[:, 1]).sum()\n",
        "            ret[i, j] = weighted_sum / weights.sum()\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huM0RzfnOEHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from multiprocessing import Process, Manager\n",
        "\n",
        "n_procs = 4\n",
        "procs = []\n",
        "manager = Manager()\n",
        "dpr_preci = manager.list([None] * n_procs)\n",
        "\n",
        "# split train into n_procs arrays\n",
        "n_imgs = test_submit.shape[0]\n",
        "splitted = np.split(test_submit, np.arange((n_imgs + n_procs - 1) // n_procs,\n",
        "                                     n_imgs, n_imgs // n_procs))\n",
        "\n",
        "def proc_func(proc_id):\n",
        "    part = splitted[proc_id]\n",
        "    arr = np.empty_like(part[:, :, :, 14])  # shape=(-1, 40, 40)\n",
        "    for i in range(part.shape[0]):\n",
        "        arr[i, :, :] = compen_ll(part[i, :, :, 14],\n",
        "                                 part[i, :, :, 10:12],\n",
        "                                 part[i, :, :, 12:14])\n",
        "        if (i + 1) % 200 == 0:\n",
        "            print(proc_id, i + 1)\n",
        "    dpr_preci[proc_id] = arr\n",
        "\n",
        "for proc_id in range(n_procs):\n",
        "    proc = Process(target=proc_func, args=(proc_id, ))\n",
        "    proc.start()\n",
        "    procs.append(proc)\n",
        "\n",
        "for proc in procs:\n",
        "    proc.join()\n",
        "\n",
        "dpr_preci = np.concatenate(dpr_preci)\n",
        "dpr_preci = dpr_preci.reshape(-1, 40, 40, 1)\n",
        "# dpr_preci = dpr_preci.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqCAPco0OEFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3t2gXonOECV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XsjsawsGh_zs",
        "colab": {}
      },
      "source": [
        "# 훈련에서 사용하는 0~8번 채널, ladtype 만을 뽑아서 X_test에 저장하기\n",
        "test_submit = np.load('/content/drive/My Drive/2020 Kaggle Study/data/test.npy')\n",
        "test_submit = test_submit[:,:,:,:10]\n",
        "del test_submit\n",
        "gc.collect()\n",
        "pred = model.predict(test_submit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2xM7q7FpIttP"
      },
      "source": [
        "## submission 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BaAuaIqhh_z3",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('/content/drive/My Drive/2020 Kaggle Study/data/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r3sFI91Gh_z8",
        "colab": {}
      },
      "source": [
        "submission.iloc[:,1:] = pred.reshape(-1, 1600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bPPRCvO_h_z_",
        "colab": {}
      },
      "source": [
        "submission.to_csv('Dacon_landtype.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fBTzEKnh_0B",
        "colab": {}
      },
      "source": [
        "# 제출파일 구글 드라이브에 올리기\n",
        "!cp Dacon_landtype.csv '/content/drive/My Drive/2020 Kaggle Study/submission'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}