{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPZZjp6n4fcp3qFjLUF9PVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/curiosity806/2020_dacon_satellite_precipitation/blob/master/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBewILWFjgrI",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19l2vB3SqhaP",
        "colab_type": "code",
        "outputId": "c6fa6ea5-5c66-4304-8a09-139fc690d048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R92vw85pL5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install pytorch tpu version\n",
        "# VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "# !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vfLpM4EpOH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import random\n",
        "import os.path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eTOpvbfrA05",
        "colab_type": "code",
        "outputId": "894db3d3-364f-4419-9792-dca1781faab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.__version__  # should be 1.5.0a0+d6149a7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.0a0+d6149a7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqLWAFJboAkO",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI9UlJxL9GHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('train.npy'):\n",
        "    !cp '/content/drive/My Drive/2020 Kaggle Study/data/train.npy' train.npy\n",
        "if not os.path.isfile('test.npy'):\n",
        "    !cp '/content/drive/My Drive/2020 Kaggle Study/data/test.npy' test.npy\n",
        "if not os.path.isfile('gmi_preci.npy'):\n",
        "    !cp '/content/drive/My Drive/2020 Kaggle Study/data/gmi_preci/near2.npy' gmi_preci.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Z2wskO9dEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = np.load('train.npy')  # float32\n",
        "test = np.load('test.npy')  # float64\n",
        "gmi_preci = np.load('gmi_preci.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOekBm82oDpM",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzaPnfektQjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train-valid split\n",
        "train, valid, train_preci, valid_preci = train_test_split(train, gmi_preci, test_size=0.025, random_state=7777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1RkguZBsWIF",
        "colab_type": "code",
        "outputId": "f38e0cd5-ae1c-4b5d-8a0a-af3cce359063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 위경도 제거\n",
        "train = np.concatenate((train[:,:,:,:10], train[:,:,:,-1:]), axis=3)\n",
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74436, 40, 40, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ5qJ0QQSKsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -9999를 포함한 이미지 제거\n",
        "is_valid = (train[:,:,:,-1].reshape(-1, 1600) < 0).sum(axis=1) == 0\n",
        "train = train[is_valid]\n",
        "train_preci = train_preci[is_valid]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUwWlFL9tPVl",
        "colab_type": "code",
        "outputId": "43d9a4e1-e731-4c4b-b6b0-933ffcbdceb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# fit scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train[:,:,:,:9].reshape(-1, 9))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS6knijytVy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 강수인 지역이 50픽셀 미만인 이미지 제거, land type 100 이상이 50픽셀 이상인 경우 살리기\n",
        "is_valid = (train[:,:,:,-1].reshape(-1, 1600) >= 0.1).sum(axis=1) >= 50\n",
        "is_valid = is_valid | ((train[:,:,:,9].reshape(-1, 1600) >= 100).sum(axis=1) >= 50)\n",
        "train = train[is_valid]  # (-1, 40, 40, 15)\n",
        "train_preci = train_preci[is_valid]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uhfLqW39xhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gmi 강수량으로 대치\n",
        "train[:, :, :, -1] = train_preci.reshape(-1, 40, 40)\n",
        "# valid[:, :, :, -1] = valid_preci.reshape(-1, 40, 40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwlYqyfCtZTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale sensor values and land type\n",
        "def scale(data):\n",
        "    # normalize sensor data\n",
        "    data[:,:,:,:9] = scaler.transform(data[:,:,:,:9].reshape(-1, 9)).reshape(-1, 40, 40, 9)\n",
        "\n",
        "    # ocean 0.0, land 1.0, coastal 0.3, inland water 0.7\n",
        "    land_type_data = data[:,:,:,9]\n",
        "    data[:,:,:,9] = np.where(land_type_data//100 == 2, 0.3,\n",
        "                             np.where(land_type_data//100 == 3, 0.7,\n",
        "                                      land_type_data//100))\n",
        "    return data\n",
        "\n",
        "train = scale(train)\n",
        "valid = scale(valid)\n",
        "test = scale(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjpCwoktXP_u",
        "colab_type": "code",
        "outputId": "08536494-8fbd-42e3-98c5-ecfc81b016b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# pytorch is channel first\n",
        "train = train.transpose((0, 3, 1, 2))\n",
        "valid = valid.transpose((0, 3, 1, 2))\n",
        "test = test.transpose((0, 3, 1, 2))\n",
        "train.shape, valid.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((51073, 11, 40, 40), (1909, 15, 40, 40), (2416, 14, 40, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LqO5tzEoP51",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGQJSqzO1kuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def r(a, n=1):\n",
        "    return np.rot90(a, n, (1, 2))\n",
        "def f_ud(a):\n",
        "    return np.flip(a, 1)\n",
        "def f_lr(a):\n",
        "    return np.flip(a, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRzlHv9h1n3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_list = [lambda x: x,              # abcd\n",
        "           lambda x: r(f_lr(x)),     # acbd\n",
        "           lambda x: f_lr(x),        # badc\n",
        "           lambda x: r(x),           # bdac\n",
        "           lambda x: r(x, 3),        # cadb\n",
        "           lambda x: f_ud(x),        # cdab\n",
        "           lambda x: f_ud(r(x, 3)),  # dbca\n",
        "           lambda x: r(x, 2)]        # dcba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69TaaeZZ1px_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MapDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, is_train, transform=None):\n",
        "        self.data = data\n",
        "        self.is_train = is_train\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.transform:\n",
        "            rand_num = random.randint(0, 7)\n",
        "            sample = self.transform[rand_num](self.data[idx])\n",
        "        else:\n",
        "            sample = self.data[idx]\n",
        "\n",
        "        sample = torch.from_numpy(sample.copy())\n",
        "\n",
        "        if self.is_train:\n",
        "            return sample[:10], sample[-1:]\n",
        "        else:\n",
        "            return sample[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyMYGNpSn74D",
        "colab_type": "text"
      },
      "source": [
        "## Define metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S41kNGgzn6_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mae(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    over_threshold = y_true >= 0.1\n",
        "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    remove_NAs = y_true >= 0\n",
        "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
        "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
        "    return (f1_score(y_true, y_pred))\n",
        "\n",
        "def maeOverFscore(y_true, y_pred):\n",
        "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seFeikIyQAgf",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBkr7Yy9YMjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BUzS5WFCImT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(768, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        # x5 = self.down4(x4)\n",
        "        # x = self.up1(x5, x4)\n",
        "        # x = self.up2(x, x3)\n",
        "        x = self.up2(x4, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YlWf2yOaFGm",
        "colab_type": "code",
        "outputId": "434531fb-6dc2-4805-d0f1-9474fb069735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "summary(UNet(10, 1), (10, 40, 40))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 40, 40]           5,824\n",
            "       BatchNorm2d-2           [-1, 64, 40, 40]             128\n",
            "              ReLU-3           [-1, 64, 40, 40]               0\n",
            "            Conv2d-4           [-1, 64, 40, 40]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 40, 40]             128\n",
            "              ReLU-6           [-1, 64, 40, 40]               0\n",
            "        DoubleConv-7           [-1, 64, 40, 40]               0\n",
            "         MaxPool2d-8           [-1, 64, 20, 20]               0\n",
            "            Conv2d-9          [-1, 128, 20, 20]          73,856\n",
            "      BatchNorm2d-10          [-1, 128, 20, 20]             256\n",
            "             ReLU-11          [-1, 128, 20, 20]               0\n",
            "           Conv2d-12          [-1, 128, 20, 20]         147,584\n",
            "      BatchNorm2d-13          [-1, 128, 20, 20]             256\n",
            "             ReLU-14          [-1, 128, 20, 20]               0\n",
            "       DoubleConv-15          [-1, 128, 20, 20]               0\n",
            "             Down-16          [-1, 128, 20, 20]               0\n",
            "        MaxPool2d-17          [-1, 128, 10, 10]               0\n",
            "           Conv2d-18          [-1, 256, 10, 10]         295,168\n",
            "      BatchNorm2d-19          [-1, 256, 10, 10]             512\n",
            "             ReLU-20          [-1, 256, 10, 10]               0\n",
            "           Conv2d-21          [-1, 256, 10, 10]         590,080\n",
            "      BatchNorm2d-22          [-1, 256, 10, 10]             512\n",
            "             ReLU-23          [-1, 256, 10, 10]               0\n",
            "       DoubleConv-24          [-1, 256, 10, 10]               0\n",
            "             Down-25          [-1, 256, 10, 10]               0\n",
            "        MaxPool2d-26            [-1, 256, 5, 5]               0\n",
            "           Conv2d-27            [-1, 512, 5, 5]       1,180,160\n",
            "      BatchNorm2d-28            [-1, 512, 5, 5]           1,024\n",
            "             ReLU-29            [-1, 512, 5, 5]               0\n",
            "           Conv2d-30            [-1, 512, 5, 5]       2,359,808\n",
            "      BatchNorm2d-31            [-1, 512, 5, 5]           1,024\n",
            "             ReLU-32            [-1, 512, 5, 5]               0\n",
            "       DoubleConv-33            [-1, 512, 5, 5]               0\n",
            "             Down-34            [-1, 512, 5, 5]               0\n",
            "         Upsample-35          [-1, 512, 10, 10]               0\n",
            "           Conv2d-36          [-1, 384, 10, 10]       2,654,592\n",
            "      BatchNorm2d-37          [-1, 384, 10, 10]             768\n",
            "             ReLU-38          [-1, 384, 10, 10]               0\n",
            "           Conv2d-39          [-1, 128, 10, 10]         442,496\n",
            "      BatchNorm2d-40          [-1, 128, 10, 10]             256\n",
            "             ReLU-41          [-1, 128, 10, 10]               0\n",
            "       DoubleConv-42          [-1, 128, 10, 10]               0\n",
            "               Up-43          [-1, 128, 10, 10]               0\n",
            "         Upsample-44          [-1, 128, 20, 20]               0\n",
            "           Conv2d-45          [-1, 128, 20, 20]         295,040\n",
            "      BatchNorm2d-46          [-1, 128, 20, 20]             256\n",
            "             ReLU-47          [-1, 128, 20, 20]               0\n",
            "           Conv2d-48           [-1, 64, 20, 20]          73,792\n",
            "      BatchNorm2d-49           [-1, 64, 20, 20]             128\n",
            "             ReLU-50           [-1, 64, 20, 20]               0\n",
            "       DoubleConv-51           [-1, 64, 20, 20]               0\n",
            "               Up-52           [-1, 64, 20, 20]               0\n",
            "         Upsample-53           [-1, 64, 40, 40]               0\n",
            "           Conv2d-54           [-1, 64, 40, 40]          73,792\n",
            "      BatchNorm2d-55           [-1, 64, 40, 40]             128\n",
            "             ReLU-56           [-1, 64, 40, 40]               0\n",
            "           Conv2d-57           [-1, 64, 40, 40]          36,928\n",
            "      BatchNorm2d-58           [-1, 64, 40, 40]             128\n",
            "             ReLU-59           [-1, 64, 40, 40]               0\n",
            "       DoubleConv-60           [-1, 64, 40, 40]               0\n",
            "               Up-61           [-1, 64, 40, 40]               0\n",
            "           Conv2d-62            [-1, 1, 40, 40]              65\n",
            "          OutConv-63            [-1, 1, 40, 40]               0\n",
            "================================================================\n",
            "Total params: 8,271,617\n",
            "Trainable params: 8,271,617\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 22.63\n",
            "Params size (MB): 31.55\n",
            "Estimated Total Size (MB): 54.25\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lurdnBaxJE29",
        "colab_type": "text"
      },
      "source": [
        "## 강수량 보정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu8n0BdhJF2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dr = [(-1, -1), (-1, 0), (-1, 1),\n",
        "      (0, -1), (0, 0), (0, 1),\n",
        "      (1, -1), (1, 0), (1, 1)]\n",
        "\n",
        "def get_dist(p1, p2):  # p1, p2: shape=(-1, 2).\n",
        "    x1, y1 = np.deg2rad(p1[:,0]), np.deg2rad(p1[:,1])\n",
        "    x2, y2 = np.deg2rad(p2[:,0]), np.deg2rad(p2[:,1])\n",
        "    dlon = x2 - x1\n",
        "    dlat = y2 - y1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(y1) * np.cos(y2) * np.sin(dlon/2)**2 \n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))    \n",
        "    return 6373.0 * c  # km, shape=(-1).\n",
        "\n",
        "# value: (40, 40)\n",
        "# ori_ll, tgt_ll: (40, 40, 2)\n",
        "def compen_ll(value, ori_ll, tgt_ll):  # ori_ll에서의 value를 tgt_ll에 대한 값으로 바꿈\n",
        "    ret = np.empty_like(value)\n",
        "    n, m = value.shape[0], value.shape[1]\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            nears = []  # (row, col, value)\n",
        "            for k in range(9):\n",
        "                ii = i + dr[k][0]\n",
        "                jj = j + dr[k][1]\n",
        "                if ii >= 0 and ii < n and jj >= 0 and jj < m:\n",
        "                    nears.append((ori_ll[ii, jj][0], ori_ll[ii, jj][1],\n",
        "                                  tgt_ll[i, j][0], tgt_ll[i, j][1],\n",
        "                                  value[ii, jj]))\n",
        "            nears = np.array(nears)  # shape=(-1, 5)\n",
        "            dists = get_dist(nears[:, 0:2], nears[:, 2:4]).reshape(-1, 1)\n",
        "            values = nears[:, 4].reshape(-1, 1)\n",
        "            nears = np.concatenate((dists, values), 1)\n",
        "            nears = nears[np.argsort(nears[:, 0])]  # sort by dist\n",
        "            nears = nears[:2, :]  # 가까운 점 2개만 고려\n",
        "\n",
        "            weights = 1 / (nears[:, 0] ** 2 + sys.float_info.epsilon)\n",
        "            weighted_sum = (weights * nears[:, 1]).sum()\n",
        "            ret[i, j] = weighted_sum / weights.sum()\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x3plaQzJPfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from multiprocessing import Process, Manager\n",
        "\n",
        "def proc_func(splitted, dpr_preci, proc_id):\n",
        "    part = splitted[proc_id]\n",
        "    arr = np.empty_like(part[:, :, :, 14])  # shape=(-1, 40, 40)\n",
        "    for i in range(part.shape[0]):\n",
        "        arr[i, :, :] = compen_ll(part[i, :, :, 14], part[i, :, :, 10:12], part[i, :, :, 12:14])\n",
        "    dpr_preci[proc_id] = arr\n",
        "\n",
        "def gmi2dpr(test, gmi_preci):\n",
        "    n_procs = 4\n",
        "    procs = []\n",
        "    manager = Manager()\n",
        "    dpr_preci = manager.list([None] * n_procs)\n",
        "\n",
        "    data = np.concatenate((test, gmi_preci), axis=3)\n",
        "    n_imgs = data.shape[0]  # split data into n_procs arrays\n",
        "    splitted = np.split(data, np.arange(n_imgs // n_procs + n_imgs % n_procs, n_imgs, n_imgs // n_procs))\n",
        "\n",
        "    for proc_id in range(n_procs):\n",
        "        proc = Process(target=proc_func, args=(splitted, dpr_preci, proc_id))\n",
        "        proc.start()\n",
        "        procs.append(proc)\n",
        "\n",
        "    for proc in procs:\n",
        "        proc.join()\n",
        "\n",
        "    dpr_preci = np.concatenate(dpr_preci)\n",
        "    return dpr_preci"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOzgiKhuoiHM",
        "colab_type": "text"
      },
      "source": [
        "## TPU training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3OJPWS9Dvvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_fn(index, flags):\n",
        "    device = xm.xla_device()  # TPU\n",
        "\n",
        "    train_dataset = MapDataset(train, True, tf_list)\n",
        "    valid_dataset = MapDataset(valid, False)\n",
        "    test_dataset = MapDataset(test, False)\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        train_dataset,\n",
        "        num_replicas=xm.xrt_world_size(),\n",
        "        rank=xm.get_ordinal(),\n",
        "        shuffle=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               batch_size=flags['batch_size'],\n",
        "                                               sampler=train_sampler,\n",
        "                                               num_workers=flags['num_workers'],\n",
        "                                               drop_last=True)  # small batch is not good for bn\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                               batch_size=len(valid),\n",
        "                                               num_workers=1,\n",
        "                                               drop_last=False)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=len(test),\n",
        "                                              num_workers=1,\n",
        "                                              drop_last=False)\n",
        "\n",
        "    # min_score 초기화\n",
        "    min_score = 2.0\n",
        "    cnt = 0\n",
        "\n",
        "    # net, loss_fn, optimizer 생성\n",
        "    net = UNet(10, 1).to(device).train()  # Training mode\n",
        "    loss_fn = torch.nn.L1Loss()  # MAE\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    # Training\n",
        "    for epoch in range(flags['num_epochs']):\n",
        "        # Training mode\n",
        "        net.train()\n",
        "\n",
        "        # 병렬 연산을 위한 loader\n",
        "        para_train_loader = pl.ParallelLoader(train_loader, [device]).per_device_loader(device)\n",
        "\n",
        "        # Update parameters\n",
        "        for batch_num, batch in enumerate(para_train_loader):\n",
        "            data, targets = batch\n",
        "\n",
        "            # Inference -> loss 계산 -> gradient 초기화 -> backpropagation\n",
        "            output = net(data)  # Acquires the network's best guesses\n",
        "            loss = loss_fn(output, targets)  # Computes loss\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()  # Updates model\n",
        "\n",
        "            xm.optimizer_step(optimizer)  # Note: barrier=True not needed when using ParallelLoader\n",
        "\n",
        "        # Boosting\n",
        "        \n",
        "\n",
        "        # Main core에서만 실행\n",
        "        if xm.is_master_ordinal():\n",
        "            print('epoch', epoch, end=': ')\n",
        "\n",
        "            # Evaluation mode\n",
        "            net.eval()\n",
        "\n",
        "            # Prediction\n",
        "            with torch.no_grad():\n",
        "                for batch_num, batch in enumerate(valid_loader):\n",
        "                    output = net(batch.to(device))  # (-1, 1, 40, 40)\n",
        "\n",
        "            # Numpy로 변환\n",
        "            output = output.cpu().numpy()\n",
        "\n",
        "            # Score 계산\n",
        "            mae_score = mae(valid_preci, output)\n",
        "            f_score = fscore(valid_preci, output)\n",
        "            mae_over_fscore = maeOverFscore(valid_preci, output)\n",
        "            print(f'mae={mae_score}, fscore={f_score}, mae/fscore={mae_over_fscore}')\n",
        "\n",
        "            # Best model 저장\n",
        "            if mae_over_fscore < min_score:\n",
        "                min_score = mae_over_fscore\n",
        "                torch.save(net.state_dict(), 'best_model.pt')\n",
        "                print('model saved.')\n",
        "                cnt = 0\n",
        "            else:\n",
        "                cnt += 1\n",
        "\n",
        "        xm.rendezvous('validation')\n",
        "\n",
        "        if cnt >= 10:\n",
        "            break\n",
        "\n",
        "    # Main core에서만 실행\n",
        "    if xm.is_master_ordinal():\n",
        "        # Best model 불러오기\n",
        "        net.load_state_dict(torch.load('best_model.pt'))\n",
        "        print('model loaded.')\n",
        "\n",
        "        # Evaluation mode로 전환\n",
        "        net.eval()\n",
        "\n",
        "        # Final validation\n",
        "        with torch.no_grad():\n",
        "            for batch_num, batch in enumerate(valid_loader):\n",
        "                output = net(batch.to(device))  # (-1, 1, 40, 40)\n",
        "\n",
        "        # Numpy로 변환\n",
        "        output = output.cpu().numpy()\n",
        "\n",
        "        # DPR 강수량으로 보정\n",
        "        output = gmi2dpr(valid.transpose((0, 2, 3, 1))[:, :, :, :-1], output.transpose((0, 2, 3, 1)))\n",
        "\n",
        "        # Score 계산\n",
        "        mae_score = mae(valid[:,-1:,:,:], output)\n",
        "        f_score = fscore(valid[:,-1:,:,:], output)\n",
        "        mae_over_fscore = maeOverFscore(valid[:,-1:,:,:], output)\n",
        "        print(f'final val: mae={mae_score}, fscore={f_score}, mae/fscore={mae_over_fscore}')\n",
        "\n",
        "        # Prediction\n",
        "        with torch.no_grad():\n",
        "            for batch_num, batch in enumerate(test_loader):\n",
        "                output = net(batch.to(device))  # (-1, 1, 40, 40)\n",
        "\n",
        "        # Numpy로 변환\n",
        "        output = output.cpu().numpy()\n",
        "\n",
        "        # 강수량 보정\n",
        "        output = gmi2dpr(test.transpose((0, 2, 3, 1)), output.transpose((0, 2, 3, 1)))\n",
        "\n",
        "        # Submission file 올리기\n",
        "        submission = pd.read_csv('/content/drive/My Drive/2020 Kaggle Study/data/sample_submission.csv')\n",
        "        submission.iloc[:,1:] = output.reshape(-1, 1600)\n",
        "        submission.to_csv('/content/drive/My Drive/2020 Kaggle Study/submission/unet_compen.csv', index=False)\n",
        "        print('submission uploaded.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNS0iV6K8CtU",
        "colab_type": "code",
        "outputId": "18bb86f6-1641-49a2-f10d-7e17ec3861fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Configures training (and evaluation) parameters\n",
        "flags = {'batch_size': 128,\n",
        "         'num_workers': 8,\n",
        "         'num_epochs': 150,\n",
        "         'seed': 7777}\n",
        "\n",
        "xmp.spawn(map_fn, args=(flags,), nprocs=8, start_method='fork')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2875: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0: mae=1.5476971864700317, fscore=0.5676967247176156, mae/fscore=2.726274164453693\n",
            "epoch 1: mae=1.4379225969314575, fscore=0.6458771579293932, mae/fscore=2.2263093788768304\n",
            "epoch 2: mae=1.4013592004776, fscore=0.6681043856469735, mae/fscore=2.097515030333262\n",
            "epoch 3: mae=1.320988655090332, fscore=0.6946790966916838, mae/fscore=1.9015808467870678\n",
            "model saved.\n",
            "epoch 4: mae=1.3048819303512573, fscore=0.7037970975577009, mae/fscore=1.8540595712506747\n",
            "model saved.\n",
            "epoch 5: mae=1.2572697401046753, fscore=0.7009101885390545, mae/fscore=1.793766992242718\n",
            "model saved.\n",
            "epoch 6: mae=1.2396239042282104, fscore=0.7210986398796115, mae/fscore=1.719076508766563\n",
            "model saved.\n",
            "epoch 7: mae=1.2726143598556519, fscore=0.7109905083670098, mae/fscore=1.789917257526888\n",
            "epoch 8: mae=1.1979784965515137, fscore=0.7281561955472788, mae/fscore=1.6452216424924524\n",
            "model saved.\n",
            "epoch 9: mae=1.208752989768982, fscore=0.730284617538452, mae/fscore=1.6551804532392356\n",
            "epoch 10: mae=1.1988269090652466, fscore=0.7353893596953262, mae/fscore=1.6301932170226154\n",
            "model saved.\n",
            "epoch 11: mae=1.1750614643096924, fscore=0.7386302924280751, mae/fscore=1.5908653046985408\n",
            "model saved.\n",
            "epoch 12: mae=1.176330327987671, fscore=0.7459595039182021, mae/fscore=1.5769356970657904\n",
            "model saved.\n",
            "epoch 13: mae=1.1708773374557495, fscore=0.7470412404838633, mae/fscore=1.567352800980686\n",
            "model saved.\n",
            "epoch 14: mae=1.1715553998947144, fscore=0.7466208947516889, mae/fscore=1.5691433915334114\n",
            "epoch 15: mae=1.1578292846679688, fscore=0.7448293872678179, mae/fscore=1.554489053481376\n",
            "model saved.\n",
            "epoch 16: mae=1.1557283401489258, fscore=0.7478410546802413, mae/fscore=1.5454195492130776\n",
            "model saved.\n",
            "epoch 17: mae=1.1494762897491455, fscore=0.7485123112342451, mae/fscore=1.5356810020741525\n",
            "model saved.\n",
            "epoch 18: mae=1.1442456245422363, fscore=0.7530896873710892, mae/fscore=1.5194013300015752\n",
            "model saved.\n",
            "epoch 19: mae=1.1262325048446655, fscore=0.7193027900813282, mae/fscore=1.5657277627750497\n",
            "epoch 20: mae=1.165650725364685, fscore=0.7433997557505281, mae/fscore=1.5679996657893582\n",
            "epoch 21: mae=1.1250317096710205, fscore=0.7546365299177502, mae/fscore=1.4908257366113287\n",
            "model saved.\n",
            "epoch 22: mae=1.1323108673095703, fscore=0.7555907220906133, mae/fscore=1.4985767881306788\n",
            "epoch 23: mae=1.1494578123092651, fscore=0.7403894662496217, mae/fscore=1.5525040663818952\n",
            "epoch 24: mae=1.1129494905471802, fscore=0.7559279067610598, mae/fscore=1.4722956162397762\n",
            "model saved.\n",
            "epoch 25: mae=1.132621169090271, fscore=0.7565782919262574, mae/fscore=1.4970308181900416\n",
            "epoch 26: mae=1.1457574367523193, fscore=0.7375689774748967, mae/fscore=1.5534239052901666\n",
            "epoch 27: mae=1.120734453201294, fscore=0.7551263080652622, mae/fscore=1.484168003172833\n",
            "epoch 28: mae=1.1164977550506592, fscore=0.7630276087973795, mae/fscore=1.4632466713566532\n",
            "model saved.\n",
            "epoch 29: mae=1.1213371753692627, fscore=0.7491515053012994, mae/fscore=1.496809414054816\n",
            "epoch 30: mae=1.1386226415634155, fscore=0.7507965052208007, mae/fscore=1.5165527303210964\n",
            "epoch 31: mae=1.1352113485336304, fscore=0.7566483121857793, mae/fscore=1.5003155101512364\n",
            "epoch 32: mae=1.1355620622634888, fscore=0.7464546274284778, mae/fscore=1.521273856989932\n",
            "epoch 33: mae=1.1253371238708496, fscore=0.7507919720656545, mae/fscore=1.4988665513937958\n",
            "epoch 34: mae=1.1095389127731323, fscore=0.7596572354662305, mae/fscore=1.4605781593515006\n",
            "model saved.\n",
            "epoch 35: mae=1.097232460975647, fscore=0.7493447378595639, mae/fscore=1.4642557145116164\n",
            "epoch 36: mae=1.1083319187164307, fscore=0.7630245493125499, mae/fscore=1.452550608574686\n",
            "model saved.\n",
            "epoch 37: mae=1.1116880178451538, fscore=0.7600687079837802, mae/fscore=1.4626149713920074\n",
            "epoch 38: mae=1.1116364002227783, fscore=0.7546209616380513, mae/fscore=1.4731054521719233\n",
            "epoch 39: mae=1.0982314348220825, fscore=0.7674248806515024, mae/fscore=1.4310603153545294\n",
            "model saved.\n",
            "epoch 40: mae=1.1428285837173462, fscore=0.7648712335976843, mae/fscore=1.4941448757686926\n",
            "epoch 41: mae=1.1029895544052124, fscore=0.7671536552749949, mae/fscore=1.4377685657157913\n",
            "epoch 42: mae=1.0890554189682007, fscore=0.7650249052829972, mae/fscore=1.4235553236136884\n",
            "model saved.\n",
            "epoch 43: mae=1.1074250936508179, fscore=0.7557605977598919, mae/fscore=1.4653118334060964\n",
            "epoch 44: mae=1.1049124002456665, fscore=0.7562385656787414, mae/fscore=1.4610630881376352\n",
            "epoch 45: mae=1.0858407020568848, fscore=0.7696725991967333, mae/fscore=1.4107824055473444\n",
            "model saved.\n",
            "epoch 46: mae=1.0934137105941772, fscore=0.7590258830287154, mae/fscore=1.4405484595285736\n",
            "epoch 47: mae=1.0907231569290161, fscore=0.7632011083069739, mae/fscore=1.4291423350188235\n",
            "epoch 48: mae=1.0877654552459717, fscore=0.7692941400350244, mae/fscore=1.4139784215678621\n",
            "epoch 49: mae=1.1061413288116455, fscore=0.7582611146339746, mae/fscore=1.4587866390417958\n",
            "epoch 50: mae=1.1075724363327026, fscore=0.7643933399799623, mae/fscore=1.4489559674422854\n",
            "epoch 51: mae=1.092463731765747, fscore=0.7675554827456611, mae/fscore=1.4233024374050425\n",
            "epoch 52: mae=1.0887675285339355, fscore=0.7632993311900585, mae/fscore=1.4263963577654453\n",
            "epoch 53: mae=1.089493989944458, fscore=0.7595310241023508, mae/fscore=1.4344296834867336\n",
            "epoch 54: mae=1.0804263353347778, fscore=0.7679518924655111, mae/fscore=1.4068930687529926\n",
            "model saved.\n",
            "epoch 55: mae=1.0771139860153198, fscore=0.7715768193107324, mae/fscore=1.3959904178802172\n",
            "model saved.\n",
            "epoch 56: mae=1.0859371423721313, fscore=0.7607916986187014, mae/fscore=1.4273775615664706\n",
            "epoch 57: mae=1.0900102853775024, fscore=0.7571394538578363, mae/fscore=1.4396425068847578\n",
            "epoch 58: mae=1.0868242979049683, fscore=0.7661656459496532, mae/fscore=1.4185237380429514\n",
            "epoch 59: mae=1.0808082818984985, fscore=0.7656348335162825, mae/fscore=1.4116496447396145\n",
            "epoch 60: mae=1.0840920209884644, fscore=0.7712997208236894, mae/fscore=1.405539054619171\n",
            "epoch 61: mae=1.0901598930358887, fscore=0.7713521772345302, mae/fscore=1.4133100079050196\n",
            "epoch 62: mae=1.079245924949646, fscore=0.7664633139371098, mae/fscore=1.4080853767120591\n",
            "epoch 63: mae=1.0672132968902588, fscore=0.7736480586066564, mae/fscore=1.3794556156022066\n",
            "model saved.\n",
            "epoch 64: mae=1.0727968215942383, fscore=0.7675112713719286, mae/fscore=1.3977601656593193\n",
            "epoch 65: mae=1.0718985795974731, fscore=0.7739724894431014, mae/fscore=1.384930931945199\n",
            "epoch 66: mae=1.078281283378601, fscore=0.7666311648016031, mae/fscore=1.406518795783329\n",
            "epoch 67: mae=1.0745365619659424, fscore=0.7665552563831202, mae/fscore=1.4017729483177663\n",
            "epoch 68: mae=1.073146939277649, fscore=0.7651387443380875, mae/fscore=1.4025518991994397\n",
            "epoch 69: mae=1.0736687183380127, fscore=0.7737380851652182, mae/fscore=1.3876382721226943\n",
            "epoch 70: mae=1.0653502941131592, fscore=0.7750566039557596, mae/fscore=1.3745449702915797\n",
            "model saved.\n",
            "epoch 71: mae=1.0702248811721802, fscore=0.7682356702136098, mae/fscore=1.3930943112354708\n",
            "epoch 72: mae=1.078535556793213, fscore=0.7624588882497824, mae/fscore=1.4145489441589265\n",
            "epoch 73: mae=1.0743788480758667, fscore=0.7694527389995419, mae/fscore=1.3962894067332259\n",
            "epoch 74: mae=1.0638487339019775, fscore=0.7719289012224588, mae/fscore=1.3781691479620828\n",
            "epoch 75: mae=1.0639511346817017, fscore=0.7736687282967782, mae/fscore=1.3752022774705506\n",
            "epoch 76: mae=1.080191731452942, fscore=0.7633816784430395, mae/fscore=1.4150085343352763\n",
            "epoch 77: mae=1.0610530376434326, fscore=0.7771339230843491, mae/fscore=1.3653411202256258\n",
            "model saved.\n",
            "epoch 78: mae=1.0519229173660278, fscore=0.7743399505538489, mae/fscore=1.3584767010483794\n",
            "model saved.\n",
            "epoch 79: mae=1.067501187324524, fscore=0.7727559100910139, mae/fscore=1.3814207503850997\n",
            "epoch 80: mae=1.0629732608795166, fscore=0.7766666826689965, mae/fscore=1.3686348954266268\n",
            "epoch 81: mae=1.0619926452636719, fscore=0.7682427907879202, mae/fscore=1.3823657309402213\n",
            "epoch 82: mae=1.0630667209625244, fscore=0.7759209509975856, mae/fscore=1.370070730257623\n",
            "epoch 83: mae=1.062087059020996, fscore=0.7737295033463678, mae/fscore=1.3726850496962855\n",
            "epoch 84: mae=1.0840996503829956, fscore=0.755804191572987, mae/fscore=1.4343655658884358\n",
            "epoch 85: mae=1.0575306415557861, fscore=0.7770894904835087, mae/fscore=1.3608863823510822\n",
            "epoch 86: mae=1.073825716972351, fscore=0.7708284357800499, mae/fscore=1.3930798707207686\n",
            "epoch 87: mae=1.0694842338562012, fscore=0.7636094362592383, mae/fscore=1.4005642714932274\n",
            "epoch 88: mae=1.0712436437606812, fscore=0.7677652721534494, mae/fscore=1.395274757906869\n",
            "model loaded.\n",
            "final val: mae=1.1665984392166138, fscore=0.7815876020804859, mae/fscore=1.4926008125656005\n",
            "submission uploaded.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}